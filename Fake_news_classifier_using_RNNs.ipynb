{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake news classifier using RNNs.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EgXKBHFDMqi"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VSlgcucDUy9"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlUjlV4tEdap"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC0KuDl5EhRh"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUROJTofEmFh"
      },
      "source": [
        "df.dropna(inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTmY6wwB4evp"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gxAIwPv4jQW"
      },
      "source": [
        "c = df.label.value_counts()*100/df.shape[0]\r\n",
        "plt.figure(figsize = (6,6))\r\n",
        "plt.title(\"Fake Vs Real News in percentages\")\r\n",
        "sns.barplot(x =c, y =c.index, orient = 'h')\r\n",
        "plt.xlabel('News Count in percentage')\r\n",
        "plt.ylabel('New Type')\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z41gUyN29TYl"
      },
      "source": [
        "c = df['author'].value_counts()[df.author.value_counts()> 100]\r\n",
        "#authors with more than 100 news\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize = (6,6))\r\n",
        "plt.title(\"Authors with more than 100 news\")\r\n",
        "sns.barplot(x =c, y =c.index, orient = 'h')\r\n",
        "plt.xlabel('News count')\r\n",
        "plt.ylabel('Authors')\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvEIXfHDHpUR"
      },
      "source": [
        "X = df.drop('label', axis =1)\n",
        "y = df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqXWs5fFIMiF"
      },
      "source": [
        "for i in [X,y]:\n",
        "  print(i.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNvO4BjHIfVu"
      },
      "source": [
        "# Performing Word embedding for the titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiqxriAvIoXs"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ocFFAixJVWk"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hTvfhFUZRp1"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtebUD0VZZyI"
      },
      "source": [
        "data = X.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_7lvjpgZTqE"
      },
      "source": [
        "# Preprocessing the data \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in data['title']:\n",
        "  c = re.sub('[^a-z,A-Z]',' ',i).lower().split()\n",
        "  rev = [ps.stem(j) for j in c if j not in stopwords.words('english')]\n",
        "  corpus.append(' '.join(rev))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY_ckEKmZxzv"
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oDM6DANcVhz"
      },
      "source": [
        "data['title'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn1Z2cAPcnGZ"
      },
      "source": [
        "# One hot representation\n",
        "vocab_size =  10000\n",
        "one_hot_represention = [one_hot(i, vocab_size) for i in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XzZJn9PdEPo"
      },
      "source": [
        "# ARRIVING AT THE MAX PADDING NUMBER TO GAIN THE MAXIMUM NUMBER OF LEN FOR ALL THE SENTENCES\n",
        "max_padding = pd.Series([len(i) for i in one_hot_represention]).max()+2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qla0d9mEdFqV"
      },
      "source": [
        "# Pad sequences\n",
        "Padding_embedded_corpus = pad_sequences(one_hot_represention, padding= 'pre', maxlen= max_padding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSWXIrkfd9LE"
      },
      "source": [
        "Padding_embedded_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUcf_agneBx1"
      },
      "source": [
        "# Creating the word embedding represation or Feature Representation and building the LSTM brained RNN\n",
        "dims = 40\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, input_length= max_padding , output_dim= dims))\n",
        "model.add(LSTM(100, activation= 'elu', recurrent_activation= 'sigmoid'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGZkLqTQiEwz"
      },
      "source": [
        "import numpy as np\n",
        "X = np.array(Padding_embedded_corpus)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwEfi196jzKp"
      },
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_FfMAJij91j"
      },
      "source": [
        "for i in [X_train, y_train, X_test, y_test]:\n",
        "  print(i.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii-BSIezkbCP"
      },
      "source": [
        "# Model training\n",
        "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs= 50, batch_size= 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc2d7iW5k5QQ"
      },
      "source": [
        "y_pred = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzF5FUtwlnyR"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEBY258IlvCL"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrZr5Tpwly3P"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNsQMu6Ql5NC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJWOOnGu5akv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}